{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "75d14c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Task 2: Model Building and Training ---\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load cleaned datasets\n",
    "fraud_df = pd.read_csv('../data/Fraud_Data.csv')\n",
    "credit_df = pd.read_csv('../data/creditcard.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2137aae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separate Features and Target\n",
    "\n",
    "# Fraud_Data\n",
    "X_fraud = fraud_df.drop(['class'], axis=1)\n",
    "y_fraud = fraud_df['class']\n",
    "\n",
    "# Creditcard\n",
    "X_credit = credit_df.drop(['Class'], axis=1)\n",
    "y_credit = credit_df['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0344bb06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use only numeric columns for modeling\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_fraud_numeric = X_fraud.select_dtypes(include=[np.number])\n",
    "X_credit_numeric = X_credit.select_dtypes(include=[np.number])\n",
    "\n",
    "# Split Fraud_Data\n",
    "X_train_fraud, X_test_fraud, y_train_fraud, y_test_fraud = train_test_split(\n",
    "    X_fraud_numeric, y_fraud, test_size=0.2, random_state=42, stratify=y_fraud\n",
    ")\n",
    "# Split Creditcard\n",
    "X_train_credit, X_test_credit, y_train_credit, y_test_credit = train_test_split(\n",
    "    X_credit_numeric, y_credit, test_size=0.2, random_state=42, stratify=y_credit\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826ebaec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 2: Model Selection\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialize models\n",
    "logreg = LogisticRegression(max_iter=1000, random_state=42)  #Logistic Regression (baseline)\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42) #Random Forest (powerful ensemble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "207e67b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression on Fraud_Data\n",
      "F1 Score: 0.0\n",
      "AUC-PR: 0.09272622425960018\n",
      "Confusion Matrix:\n",
      " [[27393     0]\n",
      " [ 2830     0]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     27393\n",
      "           1       0.00      0.00      0.00      2830\n",
      "\n",
      "    accuracy                           0.91     30223\n",
      "   macro avg       0.45      0.50      0.48     30223\n",
      "weighted avg       0.82      0.91      0.86     30223\n",
      "\n",
      "\n",
      "Random Forest on Fraud_Data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.5165165165165165\n",
      "AUC-PR: 0.5194617128113129\n",
      "Confusion Matrix:\n",
      " [[27259   134]\n",
      " [ 1798  1032]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97     27393\n",
      "           1       0.89      0.36      0.52      2830\n",
      "\n",
      "    accuracy                           0.94     30223\n",
      "   macro avg       0.91      0.68      0.74     30223\n",
      "weighted avg       0.93      0.94      0.92     30223\n",
      "\n",
      "\n",
      "Logistic Regression on Creditcard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.770949720670391\n",
      "AUC-PR: 0.699044671658662\n",
      "Confusion Matrix:\n",
      " [[56852    12]\n",
      " [   29    69]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56864\n",
      "           1       0.85      0.70      0.77        98\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.93      0.85      0.89     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n",
      "\n",
      "Random Forest on Creditcard\n",
      "F1 Score: 0.8743169398907104\n",
      "AUC-PR: 0.8733910547021404\n",
      "Confusion Matrix:\n",
      " [[56859     5]\n",
      " [   18    80]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56864\n",
      "           1       0.94      0.82      0.87        98\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.97      0.91      0.94     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Model Training and Evaluation\n",
    "from sklearn.metrics import f1_score, confusion_matrix, average_precision_score, classification_report\n",
    "\n",
    "for model, name in [(logreg, \"Logistic Regression\"), (rf, \"Random Forest\")]:\n",
    "    print(f\"\\n{name} on Fraud_Data\")\n",
    "    model.fit(X_train_fraud, y_train_fraud)\n",
    "    y_pred = model.predict(X_test_fraud)\n",
    "    y_proba = model.predict_proba(X_test_fraud)[:, 1]\n",
    "    print(\"F1 Score:\", f1_score(y_test_fraud, y_pred))\n",
    "    print(\"AUC-PR:\", average_precision_score(y_test_fraud, y_proba))\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test_fraud, y_pred))\n",
    "    print(\"Classification Report:\\n\", classification_report(y_test_fraud, y_pred))\n",
    "\n",
    "for model, name in [(logreg, \"Logistic Regression\"), (rf, \"Random Forest\")]:\n",
    "    print(f\"\\n{name} on Creditcard\")\n",
    "    model.fit(X_train_credit, y_train_credit)\n",
    "    y_pred = model.predict(X_test_credit)\n",
    "    y_proba = model.predict_proba(X_test_credit)[:, 1]\n",
    "    print(\"F1 Score:\", f1_score(y_test_credit, y_pred))\n",
    "    print(\"AUC-PR:\", average_precision_score(y_test_credit, y_proba))\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test_credit, y_pred))\n",
    "    print(\"Classification Report:\\n\", classification_report(y_test_credit, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
